{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating sentiment of a piece of text \n",
    "## uses textblob API that internally uses Naive bayes classifier trained on Amazon review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from os import path\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿I was looking forward to trying this place for a long time.  The reviews on Yelp were good and I was told by a fellow steak lover that if I wanted a great (not the best) cut of steak at a reasonable price, then Texaz is the place to go.  I went on a Thursday evening and the place was pretty busy.  I was seated right away by a very friendly hostess.  You could tell from the looks of the place that it had been around a while.  I could have sworn my booth was going to fall apart, but it was ok.  The dÃƒÂ©cor is a bit eccentric with anything and everything having to do with Texas all over the walls.  All the patrons seemed to be having a good time and enjoying their meals.  There were also plenty of wait staff bustling around.\n"
     ]
    }
   ],
   "source": [
    "filename='single_review.txt'\n",
    "\n",
    "####################################################################\n",
    "file = open(filename, 'r')\n",
    "text = file.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_document(document):\n",
    "    document = re.sub('\\n', ' ', document)\n",
    "    if isinstance(document, str):\n",
    "        document = document\n",
    "    elif isinstance(document, unicode):\n",
    "        return unicodedata.normalize('NFKD', document).encode('ascii', 'ignore')\n",
    "    else:\n",
    "        raise ValueError('Document is not string or unicode!')\n",
    "    document = document.strip()\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [sentence.strip() for sentence in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=parse_document(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [nltk.word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "#Get the sentiment of the body\n",
    "count = 0\n",
    "subjective_count=0\n",
    "positive_count=0\n",
    "negative_count=0\n",
    "subjective_sentences=[]\n",
    "positive_sentence=[]\n",
    "negative_sentence=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    blob = TextBlob(str(sentence))\n",
    "    sentiment = blob.sentiment\n",
    "    count +=1\n",
    "    if (sentiment.polarity>0 and sentiment.subjectivity >0 ):\n",
    "        positive_sentence.append(sentence)\n",
    "        positive_count +=1\n",
    "    if (sentiment.polarity<0 and sentiment.subjectivity >0 ):\n",
    "        negative_sentence.append(sentence)\n",
    "        negative_count +=1\n",
    "    \n",
    "    if (sentiment.subjectivity >0):\n",
    "        subjective_sentences.append(sentence)\n",
    "        subjective_count +=1\n",
    "\n",
    "obj_count=count-(subjective_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjective= 7\n",
      "positive = 5\n",
      "negative = 1\n",
      "count = 9\n",
      "objective sentences : 2\n"
     ]
    }
   ],
   "source": [
    "print (\"subjective=\", subjective_count)\n",
    "print (\"positive =\", positive_count)\n",
    "print (\"negative =\", negative_count)\n",
    "print  (\"count =\",count )\n",
    "print  (\"objective sentences :\",obj_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  So we can get some integer measure of the sentiment in the review text based on lexical semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final sentiment =  4\n"
     ]
    }
   ],
   "source": [
    "if positive_count == negative_count: \n",
    "    print (\"final sentiment = \",0 )\n",
    "\n",
    "if positive_count > negative_count: \n",
    "    print (\"final sentiment = \",positive_count-negative_count )\n",
    "else:\n",
    "    print (\"final sentiment = \",negative_count-positive_count )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion assessment using NRC lexicon "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each line has the following format:\n",
    "TargetWord<tab>AffectCategory<tab>AssociationFlag\n",
    "\n",
    "TargetWord is a word for which emotion associations are provided.\n",
    "\n",
    "AffectCategory is one of eight emotions (anger, fear, anticipation,\n",
    "trust, surprise, sadness, joy, or disgust) or one of two polarities\n",
    "(negative or positive).\n",
    "\n",
    "AssociationFlag has one of two possible values: 0 or 1.  0 indicates\n",
    "that the target word has no association with affect category,\n",
    "whereas 1 indicates an association.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anger = 0\n",
    "fear = 0\n",
    "anticipation = 0\n",
    "trust = 0\n",
    "surprise = 0\n",
    "sadness = 0\n",
    "joy = 0\n",
    "disgust = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "file = open(filename, 'r')\n",
    "textfromfile = file.read()\n",
    "sentences=sent_tokenize(text)\n",
    "sent = ''.join(sentences) # convert this to string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_words = TreebankWordTokenizer().tokenize(sent)\n",
    "# Remove single-character tokens (mostly punctuation)\n",
    "tok_words1 = [word for word in tok_words if len(word) > 1]\n",
    "# Lowercase all words (default_stopwords are lowercase too)\n",
    "tok_words2 = [word.lower() for word in tok_words1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_words = [word for word in tok_words2 if word not in stopwords.words('english')]\n",
    "# Calculate frequency distribution\n",
    "fdist = nltk.FreqDist(final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " NRC Emotion lexicon loaded...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "nrc_lex = pd.read_csv( \"NRC-emotion-lexicon-wordlevel-alphabetized-v0.92.txt\",sep='\\t', names=['word','emotion','association'])\n",
    "#nrc_lex.head()\n",
    "print (\"\\n NRC Emotion lexicon loaded...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion word:  forward\n",
      "emotion word:  place\n",
      "emotion word:  long\n",
      "emotion word:  yelp\n",
      "emotion word:  good\n",
      "emotion word:  told\n",
      "emotion word:  fellow\n",
      "emotion word:  lover\n",
      "emotion word:  great\n",
      "emotion word:  best\n",
      "emotion word:  cut\n",
      "emotion word:  reasonable\n",
      "emotion word:  price\n",
      "emotion word:  go.i\n",
      "emotion word:  went\n",
      "emotion word:  evening\n",
      "emotion word:  pretty\n",
      "emotion word:  right\n",
      "emotion word:  away\n",
      "emotion word:  friendly\n",
      "emotion word:  tell\n",
      "emotion word:  booth\n",
      "emotion word:  going\n",
      "emotion word:  fall\n",
      "emotion word:  apart\n",
      "emotion word:  bit\n",
      "emotion word:  eccentric\n",
      "emotion word:  time\n",
      "emotion word:  enjoying\n",
      "emotion word:  plenty\n",
      "emotion word:  wait\n",
      "emotion word:  staff\n",
      "emotion word:  bustling\n"
     ]
    }
   ],
   "source": [
    "emotion_word=[]\n",
    "for w1,w2 in fdist.items():\n",
    "    if nrc_lex['word'].str.contains(w1).any():\n",
    "        #print (\"Found\",w1)\n",
    "        #print w1,w2\n",
    "        #Change here ..every line is getting printed\n",
    "        #print (nrc_lex.loc[nrc_lex['word'] == w1])\n",
    "        anger_list = nrc_lex[nrc_lex['word']==w1][nrc_lex['emotion']=='anger'].index.tolist()\n",
    "        if len(anger_list) == 1:\n",
    "            anger += w2*int(nrc_lex.iloc[int(anger_list[0])]['association'])\n",
    "        fear_list = nrc_lex[nrc_lex['word']==w1][nrc_lex['emotion']=='fear'].index.tolist()\n",
    "        if len(fear_list) == 1:\n",
    "            fear += w2*int(nrc_lex.iloc[int(fear_list[0])]['association'])\n",
    "        anticipation_list = nrc_lex[nrc_lex['word']==w1][nrc_lex['emotion']=='anticipation'].index.tolist()\n",
    "        if len(anticipation_list) == 1:\n",
    "            anticipation += w2*int(nrc_lex.iloc[int(anticipation_list[0])]['association'])\n",
    "        trust_list = nrc_lex[nrc_lex['word']==w1][nrc_lex['emotion']=='trust'].index.tolist()\n",
    "        if len(trust_list) == 1:\n",
    "            trust += w2*int(nrc_lex.iloc[int(trust_list[0])]['association'])\n",
    "        surprise_list = nrc_lex[nrc_lex['word']==w1][nrc_lex['emotion']=='surprise'].index.tolist()\n",
    "        if len(surprise_list) == 1:\n",
    "            surprise += w2*int(nrc_lex.iloc[int(surprise_list[0])]['association'])\n",
    "        sadness_list = nrc_lex[nrc_lex['word']==w1][nrc_lex['emotion']=='sadness'].index.tolist()\n",
    "        if len(sadness_list) == 1:\n",
    "            sadness += w2*int(nrc_lex.iloc[int(sadness_list[0])]['association'])\n",
    "        joy_list = nrc_lex[nrc_lex['word']==w1][nrc_lex['emotion']=='joy'].index.tolist()\n",
    "        if len(joy_list) == 1:\n",
    "            joy += w2*int(nrc_lex.iloc[int(joy_list[0])]['association'])\n",
    "        disgust_list = nrc_lex[nrc_lex['word']==w1][nrc_lex['emotion']=='disgust'].index.tolist()\n",
    "        if len(disgust_list) == 1:\n",
    "            disgust += w2*int(nrc_lex.iloc[int(disgust_list[0])]['association'])\n",
    "        print (\"emotion word: \", w1)\n",
    "        if w1 not in emotion_word:\n",
    "            emotion_word.append(w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  So we can get the measure of the eight emotions in the review text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " anger 1\n",
      "\n",
      " fear 1\n",
      "\n",
      " anticipation 9\n",
      "\n",
      " trust 7\n",
      "\n",
      " surprise 3\n",
      "\n",
      " sadness 1\n",
      "\n",
      " disgust 0\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n anger\",anger)\n",
    "print (\"\\n fear\",fear)\n",
    "print (\"\\n anticipation\",anticipation)\n",
    "print (\"\\n trust\",trust)\n",
    "print (\"\\n surprise\",surprise)\n",
    "print (\"\\n sadness\",sadness)\n",
    "print (\"\\n disgust\", disgust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  So we can get the list of emotion words in the review text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "['forward', 'place', 'long', 'yelp', 'good', 'told', 'fellow', 'lover', 'great', 'best', 'cut', 'reasonable', 'price', 'go.i', 'went', 'evening', 'pretty', 'right', 'away', 'friendly', 'tell', 'booth', 'going', 'fall', 'apart', 'bit', 'eccentric', 'time', 'enjoying', 'plenty', 'wait', 'staff', 'bustling']\n"
     ]
    }
   ],
   "source": [
    "print(len(emotion_word))\n",
    "print(emotion_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
